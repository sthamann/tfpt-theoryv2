from __future__ import annotations

import argparse
import json
import re
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

from tfpt_suite.reference_ledger import load_reference_ledger


def _suite_root() -> Path:
    # tfpt-suite/tfpt_suite/export_reference_ledger.py -> tfpt-suite/
    return Path(__file__).resolve().parents[1]


def _data_dir() -> Path:
    return Path(__file__).resolve().parent / "data"


def _tex_escape(s: str) -> str:
    return (
        s.replace("\\", "\\textbackslash{}")
        .replace("_", "\\_")
        .replace("%", "\\%")
        .replace("&", "\\&")
        .replace("#", "\\#")
        .replace("{", "\\{")
        .replace("}", "\\}")
        .replace("^", "\\textasciicircum{}")
        .replace("~", "\\textasciitilde{}")
    )


_OBS_REF_RE = re.compile(r"^(?P<file>[A-Za-z0-9_.-]+\.json):observables\.(?P<key>[A-Za-z0-9_]+)$")


def _resolve_source_string(source: str) -> str:
    """
    Expand internal pointers like:
      global_reference_minimal.json:observables.alpha_inv_codata_2022
    to the actual citeable `source` field in that JSON.
    """
    m = _OBS_REF_RE.match(source.strip())
    if not m:
        return source

    path = _data_dir() / m.group("file")
    if not path.is_file():
        return source

    try:
        payload = json.loads(path.read_text(encoding="utf-8"))
        obs = payload.get("observables", {})
        if not isinstance(obs, dict):
            return source
        entry = obs.get(m.group("key"), {})
        if isinstance(entry, dict) and isinstance(entry.get("source"), str):
            return str(entry["source"])
    except Exception:
        return source

    return source


def _cite_key_for(*, version: str, source: str, dataset_id: str) -> str:
    v = version.lower()
    s = source.lower()

    if "codata" in v and "2022" in v:
        return "codata2022"
    if "pdg" in v and "2024" in v:
        return "pdg2024"
    if "planck" in v and "2018" in v:
        return "planck2018"
    if "nufit" in v and "5.3" in v:
        return "nufit53_2024"
    if "sh0es" in v and "2022" in v:
        return "riess2022"
    if "minami" in v and "komatsu" in v:
        return "minamiKomatsu2020"

    # Fallback heuristics by source string.
    if "nist" in s or "codata" in s:
        return "codata2022"
    if "pdg" in s:
        return "pdg2024"
    if "planck" in s or "arxiv.org/abs/1807.06209" in s:
        return "planck2018"
    if "nufit" in s:
        return "nufit53_2024"
    if "riess" in s or "sh0es" in s:
        return "riess2022"
    if "minami" in s or "komatsu" in s:
        return "minamiKomatsu2020"

    # Internal / suite-native sources (still citeable via a stable key).
    if dataset_id.startswith("m_") or dataset_id.endswith("_pdg"):
        return "pdg2024"
    return "tfptSuiteData"


def _fmt_num(x: Any) -> str:
    if x is None:
        return "---"
    try:
        # Preserve JSON numeric formatting; siunitx handles scientific notation.
        return "\\num{{{}}}".format(str(x))
    except Exception:
        return "---"


def _fmt_units(units: str) -> str:
    u = units.strip()
    if not u or u.lower() == "dimensionless":
        return "dimensionless"
    if u == "km s^-1 Mpc^-1":
        return r"\(\mathrm{km\,s^{-1}\,Mpc^{-1}}\)"
    if u.lower() == "degrees":
        return r"\(\mathrm{deg}\)"
    # Common particle-physics units
    if u in {"GeV", "MeV", "eV"}:
        return rf"\(\mathrm{{{u}}}\)"
    return rf"\texttt{{{_tex_escape(u)}}}"


def export_reference_ledger_tex(*, write_path: Path) -> Path:
    ledger = load_reference_ledger()
    datasets = ledger.get("datasets", {})
    if not isinstance(datasets, dict):
        raise ValueError("Invalid references.json: datasets is not a dict")

    rows: list[dict[str, Any]] = []
    for dataset_id, ds in datasets.items():
        if not isinstance(ds, dict):
            continue
        version = str(ds.get("version", ""))
        units = str(ds.get("units", ""))
        value = ds.get("value", None)
        sigma = ds.get("sigma", None)
        source_raw = str(ds.get("source", ""))
        source_resolved = _resolve_source_string(source_raw)
        cite_key = _cite_key_for(version=version, source=source_resolved, dataset_id=str(dataset_id))
        rows.append(
            {
                "dataset_id": str(dataset_id),
                "version": version,
                "units": units,
                "value": value,
                "sigma": sigma,
                "source": source_resolved,
                "cite_key": cite_key,
            }
        )

    rows = sorted(rows, key=lambda r: r["dataset_id"])

    now = datetime.now(tz=timezone.utc).isoformat()
    lines: list[str] = []
    lines.append("% AUTO-GENERATED by tfpt_suite/export_reference_ledger.py â€” do not edit by hand.")
    lines.append(f"% generated_at_utc: {now}")
    lines.append("% source: tfpt_suite/data/references.json (+ dereferenced global_reference*.json observables where applicable)")
    lines.append("")
    lines.append(r"\begin{longtable}{@{}lrrllp{0.36\textwidth}@{}}")
    lines.append(r"\caption{Reference ledger used by the TFPT suite (auto-generated).}\label{tab:reference-ledger}\\")
    lines.append(r"\toprule")
    lines.append(r"Key & Value & $\sigma$ & Units & Version & Source (stable key)\\")
    lines.append(r"\midrule")
    lines.append(r"\endfirsthead")
    lines.append(r"\toprule")
    lines.append(r"Key & Value & $\sigma$ & Units & Version & Source (stable key)\\")
    lines.append(r"\midrule")
    lines.append(r"\endhead")
    lines.append(r"\midrule")
    lines.append(r"\multicolumn{6}{r}{\small Continued on next page.}\\")
    lines.append(r"\midrule")
    lines.append(r"\endfoot")
    lines.append(r"\bottomrule")
    lines.append(r"\endlastfoot")

    for r in rows:
        key = _tex_escape(r["dataset_id"])
        value = _fmt_num(r["value"])
        sigma = _fmt_num(r["sigma"])
        units = _fmt_units(str(r["units"]))
        version = _tex_escape(str(r["version"]))
        src = str(r["source"]).replace("`", "")
        src_tex = _tex_escape(src)
        cite_key = str(r["cite_key"])
        source_cell = rf"\cite{{{cite_key}}} {src_tex}"
        lines.append(rf"\texttt{{{key}}} & {value} & {sigma} & {units} & {version} & {source_cell}\\")

    lines.append(r"\end{longtable}")
    lines.append("")

    write_path.parent.mkdir(parents=True, exist_ok=True)
    write_path.write_text("\n".join(lines) + "\n", encoding="utf-8")
    return write_path


def main() -> None:
    parser = argparse.ArgumentParser(description="Export a paper-ready reference ledger TeX table from tfpt_suite/data/references.json.")
    parser.add_argument(
        "--write-tex",
        default="out/paper_reference_ledger.tex",
        help="Path (relative to tfpt-suite/) to write the TeX output (default: out/paper_reference_ledger.tex).",
    )
    args = parser.parse_args()

    out = export_reference_ledger_tex(write_path=(_suite_root() / Path(str(args.write_tex))).resolve())
    print(str(out))


if __name__ == "__main__":
    main()

